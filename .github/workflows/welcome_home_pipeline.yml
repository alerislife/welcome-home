name: Welcome Home Pipeline

on:
  schedule:
    # Run daily at 00:15 EST (05:15 UTC)
    - cron: '15 5 * * *'
  workflow_dispatch:
    # Allow manual triggering with optional table selection
    inputs:
      tables:
        description: 'Comma-separated list of tables to process (leave empty for all)'
        required: false
        type: string
      step_type:
        description: 'Step type to run'
        required: false
        default: 'both'
        type: choice
        options:
          - 'both'
          - 'api_blob_only'
          - 'snowflake_only'

jobs:
  process-table:
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      fail-fast: false # Don't stop other tables if one fails
      matrix:
        table: ["Prospects", "Residents", "Activities", "DepositTransactions"]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Step 1 - Download from API and Upload to Azure Blob
        id: api_blob
        if: ${{ github.event.inputs.step_type != 'snowflake_only' }}
        env:
          WELCOME_HOME_API_KEY: ${{ secrets.WELCOME_HOME_API_KEY }}
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          python -c "
          import sys, os
          sys.path.insert(0, os.getcwd())
          from main import process_table
          from utils.config_utils import load_config
          config = load_config('config.ini')
          # Only run API download and blob upload
          success = process_table('${{ matrix.table }}', config, snowflake_load=False)
          if not success:
              sys.exit(1)
          "

      - name: Step 2 - Load from Azure Blob to Snowflake
        id: snowflake
        # This step will only run if:
        # 1. The workflow is not set to 'api_blob_only'.
        # 2. The previous 'api_blob' step was successful OR the workflow is set to 'snowflake_only'.
        if: ${{ github.event.inputs.step_type != 'api_blob_only' && (steps.api_blob.outcome == 'success' || github.event.inputs.step_type == 'snowflake_only') }}
        env:
          WELCOME_HOME_API_KEY: ${{ secrets.WELCOME_HOME_API_KEY }}
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          python -c "
          import sys, os
          sys.path.insert(0, os.getcwd())
          from main import process_table
          from utils.config_utils import load_config
          config = load_config('config.ini')
          # Only run Snowflake loading
          success = process_table('${{ matrix.table }}', config, api_download=False, blob_upload=False)
          if not success:
              sys.exit(1)
          "

      - name: Upload logs for ${{ matrix.table }}
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: logs-${{ matrix.table }}
          path: welcome_home_pipeline_*.log
          retention-days: 7
