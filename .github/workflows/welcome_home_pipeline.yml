name: Welcome Home Pipeline

on:
  schedule:
    # Run daily at 00:15 EST (05:15 UTC)
    - cron: '15 5 * * *'
  workflow_dispatch:
    # Allow manual triggering with optional table selection
    inputs:
      tables:
        description: 'Comma-separated list of tables to process (e.g., Prospects,Activities). Leave empty for all.'
        required: false
        type: string
        default: ''
      step_type:
        description: 'Step type to run'
        required: false
        default: 'both'
        type: choice
        options:
          - 'both'
          - 'api_blob_only'
          - 'snowflake_only'

jobs:
  process-table:
    # The 'if' condition was removed from here.
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        table: ["Prospects", "Residents", "Activities", "DepositTransactions"]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Step 1 - Download from API and Upload to Azure Blob
        id: api_blob
        # The 'if' condition is now on the step, where the 'matrix' context is available.
        if: ${{ (github.event.inputs.tables == '' || contains(github.event.inputs.tables, matrix.table)) && github.event.inputs.step_type != 'snowflake_only' }}
        env:
          WELCOME_HOME_API_KEY: ${{ secrets.WELCOME_HOME_API_KEY }}
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          python -c "
          import sys, os
          sys.path.insert(0, os.getcwd())
          from main import api_download_and_upload
          from utils.config_utils import load_config
          config = load_config('config.ini')
          success = api_download_and_upload('${{ matrix.table }}', config)
          if not success:
              sys.exit(1)
          "

      - name: Step 2 - Load from Azure Blob to Snowflake
        id: snowflake
        # The 'if' condition is now on the step, combined with the original step logic.
        if: ${{ (github.event.inputs.tables == '' || contains(github.event.inputs.tables, matrix.table)) && github.event.inputs.step_type != 'api_blob_only' && (steps.api_blob.outcome == 'success' || github.event.inputs.step_type == 'snowflake_only') }}
        env:
          WELCOME_HOME_API_KEY: ${{ secrets.WELCOME_HOME_API_KEY }}
          AZURE_CONNECTION_STRING: ${{ secrets.AZURE_CONNECTION_STRING }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
        run: |
          python -c "
          import sys, os
          sys.path.insert(0, os.getcwd())
          from main import snowflake_load
          from utils.config_utils import load_config
          config = load_config('config.ini')
          success = snowflake_load('${{ matrix.table }}', config)
          if not success:
              sys.exit(1)
          "

      - name: Upload logs for ${{ matrix.table }}
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: logs-${{ matrix.table }}
          path: welcome_home_pipeline_*.log
          retention-days: 7